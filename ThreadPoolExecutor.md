- 功能强大之处：
	- 处理高峰期：工作队列，救急线程（非核心线程）和拒绝策略
		- 【高峰期】的含义：生产者的生产速度远远快于消费者的消费速度
		- 生产者往往是cpu型操作
		- 消费者往往是IO型操作（访问数据库或者中间层）
	- 高峰过后回归平静：keepAliveTime
		- 对超过keepAliveTime的非核心空闲线程，进行线程销毁
- 线程池状态：AtomicInteger 类型
	- ![[Pasted image 20251202194140.png]]![[Pasted image 20251202194239.png]]
	- **`SHUTDOWN`vs `STOP`**：
		- `shutdown()`方法触发 `SHUTDOWN`，是一种**温和的关闭**，会清理由空闲线程执行队列中的剩余任务。
		- `shutdownNow()`方法触发 `STOP`，是一种**强制的关闭**，会尝试中断所有任务（包括正在执行的）并清空队列，目的是让线程池尽快结束
	-  **`TIDYING`状态的作用**：这是一个短暂的中间状态，用于触发 `terminated()`这个空方法。
		- 可拓展的接口：你可以重写 `terminated()`方法来在线程池完全终止前执行一些自定义的清理工作。
	- 状态的值：使用 int 的高3位来表示线程池状态，低 29 位表示线程数量
		- 目的：可以使用一次cas原子操作进行赋值
	- 状态流向不可逆
- Worker线程的生命周期：循环执行以下任务
	1. 获取任务
		- 首先尝试执行创建时分配给它的第一个任务 (`firstTask`)。
		- 之后，则通过 `getTask()`方法从任务队列中获取任务。 
			- 根据配置决定是从队列中无限期等待任务，还是超时获取
				- 配置：
					- `allowCoreThreadTimeOut`
					- 当前线程数是否大于 `corePoolSize`
				- 如果超时了，返回null，Worker退出循环
					- 线程随之终止并被回收
	2. 执行任务
		- 会先获取 Worker 本身的锁，然后执行任务的 `run()`方法
		- 执行前后有相应的钩子函数（如 `beforeExecute`, `afterExecute`）可供扩展

- 构造方法：参数的作用![[Pasted image 20251202195724.png]]
	- `corePoolSize`：核心线程数，线程池会长期维持的线程数量
		- 核心线程的含义：线程池长期持有这些线程
			- 【长期持有】即使这些线程处于空闲状态，也不会被回收
			- 除非设置了 `allowCoreThreadTimeOut`为 true
		- 配置：
			- cpu密集型：和cpu核心数量一样
			- IO密集型：N * (1 + 平均IO等待时间/平均CPU计算时间)
				- 通常可设为 2N 或更高
				- 目的：在IO等待期间让其他线程使用CPU，提高资源利用率
	- `maximumPoolSize`:最大线程数，线程池允许创建的最大线程数量
		- 最大线程数与核心线程数的差值，代表能创建几个非核心线程来处理任务
			- 【非核心线程/救急线程】：这些线程等待新任务一段时间后仍然处于空闲状态，会被回收
			- 【创建】前提：工作队列是有界队列
			- 【创建】时机：存储任务的阻塞队列满了
		- 配置：通常设置为 `corePoolSize`的 1-2 倍
			- 需注意设置过大会导致资源耗尽和频繁上下文切换。
	- `keepAliveTime`：空闲线程存活时间
		- 多余的空闲线程在等待新任务的最长时间
			- 【多余】：线程池中的线程数量超过 `corePoolSize`
			- 【等不到的后果】：被回收
		- 配置：
			- 通常60s
			- 流量波动大时可适当调低，如 10 秒
	- `unit`：`keepAliveTime`的时间单位
	- `workQueue`：工作队列。存储等待执行的任务的阻塞队列
		- 阻塞队列的选择：
			- 无界队列：`LinkedBlockingQueue`
				- 可能导致任务无限堆积，引发内存溢出（OOM）风险
			- 延迟队列：`DelayQueue`
				- 【延迟】：元素有过期时间，过期的元素才能被取出。
				- 无界
			- 优先级丢列：`PriorityBlockingQueue `
				- 优先级：按照元素自然优先级升序排列
				- 无界
			- 有界队列：`ArrayBlockingQueue
				- 可以避免队列无限制增长导致内存耗尽
				- 需要合理设置队列大小，根据吞吐量和延迟要求设定
			- 同步队列：`SynchronousQueue`
				- 【不存储元素】：容量为0，不存储队列
					- 任务提交后会立即寻找空闲线程或创建新线程来执行
				- 通常与 `CachedThreadPool`配合使用
		- put的时机：所有核心线程都在忙碌
	- `threadFactory`：线程工厂。用于创建新线程的工厂
		- 自定义线程的名称，便于监控和调试
		- 还可以设置守护线程
	- `handler`：拒绝策略处理器。决定如何拒绝新提交的任务。
		- 使用时机：线程池无法再接受新任务时
			1. 任务队列已满
			2. 线程数达到 `maximumPoolSize`
		- 内置拒绝策略处理器选择：要考虑任务队列的有界无界
			- 抛出异常：`ThreadPoolExecutor.AbortPolicy`
				- 直接抛出 `RejectedExecutionException`异常，让调用者感知到任务被拒绝
			- 让生产者自己执行：`ThreadPoolExecutor.CallerRunsPolicy`
				- 降低新任务提交速度，自然起到“削峰填谷”的作用
			- 静默丢弃新任务：`ThreadPoolExecutor.DiscardPolicy`
			- 淘汰即将执行的任务，重新提交被拒绝的任务：`ThreadPoolExecutor.DiscardOldestPolicy`
- 工厂方法创建线程池：
	- 创建 线程数量固定的线程池：`newFixedThreadPool(int nThreads)`
		- 使用的构造：
			- 工作队列：无界的LinkedBlockingQueue
				- 问题：可能导致任务在队列中大量堆积，最终引发内存溢出（OOM）
			- 【线程数量固定】：corePoolSize = maximumPoolSize
		- 使用场景：处理稳定且耗时的任务
			- 示例：在服务器后端处理持续稳定的请求流，或者执行数据转换、报表生成等需要较长时间的操作
			- 固定数量的线程避免了频繁创建和销毁的开销，提供了稳定的并发处理能力
			- 无界队列确保了所有提交的任务都能被接纳，不会轻易被拒绝。
	- 线程数可弹性伸缩：`newCachedThreadPool()`
		- 使用场景：适合处理大量执行时间短的异步任务
			- 示例：Web服务器处理高并发的短连接请求，或者需要快速响应的异步日志记录
		- 使用的构造：【线程数弹性收缩】
			- 【弹性的实现基础 】工作队列：SynchronousQueue
				- 任务提交后会立即寻找空闲线程或创建新线程来执行
			- 【弹性的访问】最大线程数量无上限，核心线程数量为0
				- 问题：在高并发情况下可能创建大量线程，耗尽系统资源
			- 【收缩的方式】闲置线程超过60秒会被回收
	- 单个工作线程 ：`newSingleThreadExecutor()`
		- 使用场景：确保所有任务在单个线程中按提交顺序依次执行
		- 使用的构造：
			- 工作队列：使用无界的LinkedBlockingQueue
			- 和newFixedThreadPool(1)的区别：
				- 无法再配置线程数

- 提交任务：
	- 触发并遗忘（异步）：`execute(Runnable command)`
		- 【遗忘】：异步执行一个不需要返回结果的任务
			- 无返回值，不关心执行结果
			- 任务可能抛出异常，务必在 `Runnable`的 `run`方法内部进行 `try-catch`**​ 处理
				- 任务中未捕获的异常会**直接抛出**，可能导致线程退出。
				- 线程终止，但线程池会创建一个新线程来补充
		- 适合场景：不关心执行结果的异步操作
	- 需要获取任务返回值或管理任务生命周期（同步）：`Future<T> submit(Callable<T> task)`
		- 三种重载版本：
			- `<T> Future<T> submit(Callable<T> task);`
			- `Future<?> submit(Runnable task);`：通过 get() 获取结果为 null
			- `<T> Future<T> submit(Runnable task, T result);`:可以设置返回预设的结果
		- 实现需求的方式：返回 [[Future]]`<T>`对象，用于获取任务结果或异常
			- 异常被封装在 `Future`对象中，调用 `Future.get()`时才会抛出。
		- 使用场景：需要同步的场景
	- 等待所有任务完成并获取返回值：`invokeAll(Future<T>[] tasks)`
		- 参数：任务列表
			- 可以设置超时时间
		- 效果：阻塞直到所有任务都执行完毕
		- 返回值：一个包含各任务结果的 `Future`列表
			- 结果的顺序与提交时的任务列表顺序一致
	- 获取首个完成的任务结果：`invokeAny(Future<T>p[] tasks)`
		- 参数：任务列表
			- 可以设置超时时间
		- 效果：任务赛跑得到第一名
			- 只要有任意一个任务成功完成（未抛出异常），就返回该任务的结果
				- 取消其他所有任务
- 关闭线程池：
	- 平缓关闭：shutdown()
		- 【平缓】线程进入`SHUTDOWN`状态
			- 【`SHUTDOWN`状态】不再接受新任务，但会继续执行队列中已存在的任务
	- 强制关闭：shutdownNow()
		- 【强制 】线程池进入 `STOP`状态
			- 【STOP状态】不再接受新任务，而且会让工作线程停止正在执行的任务
				- 【停止】的方式：中断（`interrupt()`）
				- 其效果高度依赖于任务对中断的响应
			- 返回值：包含所有未被执行任务的列表
	- 等待关闭：awaitTermination(timeout，unit)
		- 【等待】阻塞当前线程，等待线程池达到终止状态（所有任务完成或等待超过设置的超时）
		- 返回值：是否在等待时间内所有任务完成
		- 使用方式：和shutdownNow()组合使用
			- 先尝试等待关闭（awaitTermination）
			- 等待超时则强制关闭（shutdownNow）
- 问题：饥饿
	- 饥饿问题的含义：在工作线程模式中，某些任务永远无法获得执行所需的线程资源而无限期等待的现象
	- 成因：由于线程池资源配置或任务调度方式不当，特别是固定大小的线程池处理多阶段且有依赖关系的任务
		- 执行某一流程后都等待另一流程才能进行下一阶段的任务
			- 比如点餐的任务，要等待做菜完的结果返回，才能继续进行下一步，于是进入阻塞等待
		- 但是已经某一空闲线程完成新的任务
			- 线程大小固定，没有多余线程完成做菜任务
	- 解决方法：
		- 线程池隔离
			- 【隔离】的依据：任务类型和职责
			- 设计目的：使得同一线程池的线程 责任单一
				- 避免出现同一线程池的线程处理多阶段且有依赖关系的任务
		- 设置合适的线程池数量和使用弹性线程池
- 问题：
	- Timer实现定时功能的局限性
		- 单线程阻塞：Timer 的单线程模型，所有任务都在一条线程上顺序执行
			- 存在一个执行时间很长的任务，它会直接“卡住”整个调度队列
		- 异常处理脆弱：一旦某个 TimerTask 的 `run`方法中抛出了未捕获的异常，整个 Timer 线程就会立即终止
		- 调度基础依赖绝对时间currentTimeMillis
			- 当系统时间被手动调整或由 NTP 同步时，会导致调度时间混乱
	- 解决方法：支持定时与周期性任务：`newScheduledThreadPool(int corePoolSize)`
		- 使用场景：创建一个支持定时及周期性任务执行的线程池
		- 使用的队列：延迟队列`DelayedWorkQueue` 
		- 特点：
			- 基于线程池实现，多线程
				- 任务在不同线程执行，互不干扰：不会出现一个异常，其余全终止情况
				- 任务阻塞，不影响其他任务的定时与调度
			- 调度基础：相对时间​ (`nanoTime`)
				- 不受系统时钟更改影响
		- 使用的示例：
			```
			ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(3);
			// 延迟5秒执行
			scheduledThreadPool.schedule(new Task(), 5, TimeUnit.SECONDS);
			// 延迟1秒后，每3秒固定频率执行一次（不论任务执行时间）
			scheduledThreadPool.scheduleAtFixedRate(new Task(), 1, 3, TimeUnit.SECONDS);
			// 延迟1秒后，每次任务执行完成后，间隔3秒再开始下一次执行
			scheduledThreadPool.scheduleWithFixedDelay(new Task(), 1, 3, TimeUnit.SECONDS);
			```
- 问题：
	- 创建线程的数量受限于内存和系统资源，远远不够几万级别的高并发情况
	- 阻塞代价高：在I/O密集型应用中，线程大部分时间在等待。
		- 在线程池模型中，一个被阻塞的平台线程无法处理其他任务，即使CPU是空闲的。
		- 传统线程池的解决方法是，增加线程数量，但是很快就会碰到内存和系统资源的瓶颈
	- 解决方法：虚拟线程执行器，提供挂载-卸载调度机制
		1. **提交任务**：当你向 `newVirtualThreadPerTaskExecutor()`提交一个任务时，它会立即创建一个新的虚拟线程来执行该任务。
		2. **挂载到载体线程**：JVM 的调度器会将这个虚拟线程**挂载**到一个实际的平台线程（称为**载体线程**）上开始执行。默认情况下，这些载体线程是一个高效的 `ForkJoinPool`。
		3. **遇到阻塞时卸载**：当虚拟线程中的代码执行到阻塞操作（如 `Thread.sleep()`, 网络I/O, 文件操作）时，魔法发生了。JVM 不会让载体线程空等，而是会将当前虚拟线程从载体线程上**卸载**。虚拟线程的状态（栈帧、执行点）被保存到堆内存中，然后该载体线程被释放。
		4. **载体现身**：被释放的载体线程不会闲着，它会立刻去执行队列中的下一个虚拟线程任务。
		5. **恢复执行**：当之前阻塞的操作完成时（如睡眠时间到、网络数据到达），JVM 调度器会找到一个空闲的载体线程，并将之前卸载的虚拟线程重新**挂载**上去，从上次阻塞的地方继续执行。
- 性能瓶颈：
	- 全局锁竞争
		- 对工作线程集合的任何操作需要先获取全局锁
			- 【任务和操作】新增线程、中断线程
		- 存在大量短时任务：频繁创建和销毁线程
	- 流量变化幅度大：
		- ThreadPoolExecutor默认的参数在创建后是固定的
			- 无法根据运行时负载动态调整
		- 所有任务共享同一个队列，一个耗时任务可能会阻塞大量快速任务
	- 工作队列的OOM问题：
		- 使用无界队列（如 `LinkedBlockingQueue`）
			- 当任务提交速度持续高于处理速度时，队列会无限增长，最终耗尽内存
		- 解决措施:
			- 使用有界队列以及合适的拒绝策略