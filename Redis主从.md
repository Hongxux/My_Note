- 需求背景：单点Redis实例的问题
	- 单点故障风险
	- 高并发读的性能瓶颈
- 解决措施：Redis主从复制架构
	- 实现高可用：从节点又主节点的副本，在主节点故障的时候，可以升级为主节点，实现故障转移，降低服务中断的风险和时间
	- 提升读性能：Redis主从复制架构支持读写分离
		- 主节点专注于处理写操作
		- 多个从节点可以共同分担大量的读请求
	- 数据备份可以在从节点上进行，而不影响主节点的性能
- 问题：
	- 异步的主从复制具有复制延迟，存在一致性问题
	- 没有扩展写性能和存储容量（分片集群）
---
**核心架构**：
- 主节点（Master）‍：负责处理写命令，数据变更后异步同步给从节点
- 从节点（Slave/Replica）‍：复制主节点的数据副本，默认处理读请求。
- 拓扑：支持一主多从、**树状级联复制**（从节点可以作为其他从节点的主节点）

**数据同步**
- 同步基础
	
	- 复制偏移量
		- 主从节点各自维护一个**复制偏移量**（`offset`），记录已同步的数据量。
			- 主节点每次向从节点传播N个字节的数据，自身的偏移量就会增加N
			- 从节点收到后，也会增加同样的偏移量
		- 作用：对比主从节点的偏移量，可以快速判断数据是否处于一致状态
			- 偏移量相同，则数据同步；
			- 偏移量不同，则存在延迟
	- 复制积压缓冲区
		- 数据结构：环形队列（`repl_backlog_buffer`）![[Pasted image 20251123132922.png]]
			- 大小通过 `client-output-buffer-limit replica` 配置
		- 在主节点进行命令传播时，不仅会将写命令发送给从节点，还会将其写入这个缓冲区，并为每个字节记录对应的偏移量
		- 作用：支持增量复制 
			- 触发时机：从节点短暂断线重连
			- 具体流程
				- 从节点重连后将自己的偏移量发送给主节点
					- 如果该偏移量之后的数据仍然存在于**积压缓冲区**中，主节点就会将这部分数据发送给从节点，完成增量同步
					- 如果该偏移量之后的数据被覆盖了，则进行代价较高的全量同步
		- 风险：如果从节点同步太慢，缓冲区被写满，会导致连接断开并触发全量同步。
	- 复制ID
		- 数据集的标记，每一个master都有唯一的replid，slave则会继承master节点的replid
		- 如果ID相同，说明断线前连接的就是当前主节点，可以尝试增量同步
		- 如果ID不同（例如主节点已重启变更），则必须进行全量同步
			- 因为主节点可能持有了不同的数据集
- 同步流程
	- **首次连接：全量同步**
		1. **握手与身份确认**
			- 从节点向主节点发送 `PSYNC ? -1` 命令。
			    - `?` 表示不知道主节点的ID。
			    - `-1` 表示请求全量同步。
			- 主节点回复 `+FULLRESYNC <runid> <offset>`。
			    - `runid` 是主节点的唯一身份标识。
			    - `offset` 是主节点当前的复制偏移量。
			- 从节点会保存这两个信息，用于后续识别和断线重连。
		2. **主节点生成并传输数据快照**（RDB）**‍
			- 在生成和传输RDB的这段时间里，主节点收到的新写命令，会被同时记录到一个临时的“复制缓冲区” 中。
		3. **从节点加载RDB后加载复制缓冲区**
			- 从节点收到RDB文件后，会**清空自身旧数据**，然后将RDB文件加载到内存。
			- 加载完成后，主节点再将**复制缓冲区**里暂存的新写命令发送给从节点执行。
	-  **正常运营：增量同步**
		在全量同步完成后，主从进入正常的实时同步状态，这个过程是**持续且异步**的。
		- 实现机制
			- **命令传播**
				- 主节点每执行一个写命令（如 `SET`, `HSET`），除了返回结果给客户端，还会**异步地**将这个命令发送给所有从节点。
				- 从节点接收到命令后，在本地执行一遍，从而保持数据实时更新。
			- 保障机制：**复制积压缓冲区**
				- 主节点传播给从节点的**所有写命令**，都会在这里额外存一份
				- 作用：为**可能的断线重连场景**提供数据备份。
	- **连接中断后：重同步决策**
		从节点重连并发送 `PSYNC` 命令之后
		- **1. 从节点发起重同步请求**
			- 从节点断线重连后，会向主节点发送 `PSYNC <replid> <offset>`。
			    - `<replid>` 是它上次保存的主节点的复制ID。
				-  `<offset>` 是它断开连接前最后的复制偏移量。
			**2. 主节点的两步验证决策**  
			主节点收到请求后，会进行两步检查，任何一步不通过都会触发全量同步：
			- **第一步：检查 `replid` 是否匹配**
			    - **匹配**：说明主节点没变（未重启），进入下一步检查。
			    - **不匹配**：说明主节点可能重启过，生成了新的 `replid`。从节点必须**全量同步**，因为主节点可能已经有了新数据集。
			- **第二步：检查 `offset` 是否在积压缓冲区中**
			    - 主节点检查从节点提供的 `offset` 之后的数据，是否还保存在 **复制积压缓冲区** 这个环形队列里。
			    - **如果在**：说明断线期间丢失的数据还在缓冲区里，主节点会回复 `+CONTINUE`，然后**仅将 `offset` 之后缺失的命令**发送给从节点，这就是高效的**部分重同步**。
			    - **如果不在**：说明从节点断开时间太长，它缺失的数据已经被新数据从环形缓冲区中“挤掉”了。此时只能触发**全量同步**。

----
提高主从复制效率
1. 优化全量同步的性能：
	- 无磁盘同步：不将数据写入磁盘再网络传输给从节点，而是直接网络传输给从节点
		- 配置方式：在master中配置repl-diskless-syncyes启用无磁盘复制，避免全量同步时的磁盘IO
		- 使用场景：当网络速度快的时候使用
	- Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
 2. 尽量避免增量同步退化成全量同步:
	 - 适当提高repl baklog（复制缓冲区）的大小，
	 - 发现slave宕机时尽快实现故障恢复：哨兵机制
3. 减轻mastear压力:使用主-从-从的链式结构![[Pasted image 20251123133930.png]]
	- 实现方式:在指定replicaof的时候选择从节点而不是主节点




----

 **搭建主从架构**
在单台 Rocky Linux 虚拟机上搭建 Redis 一主二从架构，是通过创建三个在不同端口上运行的 Redis 实例来实现的。这种方法非常适合学习和功能测试。其核心架构和配置差异可以通过下表快速掌握：

|实例角色|运行端口|核心配置项|说明|
|---|---|---|---|
|**主节点 (Master)**​|6379|无需特殊配置|默认处理写请求，数据变更会自动同步到从节点|
|**从节点1 (Slave)**​|6380|`replicaof 127.0.0.1 6379`|指定主节点地址和端口，复制主节点数据|
|**从节点2 (Slave)**​|6381|`replicaof 127.0.0.1 6379`|同上，实现一个主节点对应多个从节点|

### 🔧 详细配置步骤

#### 1. 准备配置文件

首先，为每个实例创建独立的配置文件、数据目录和日志文件，这是避免冲突的关键。

```
# 创建专用的配置、数据和日志目录
sudo mkdir -p /etc/redis /var/lib/redis/{6379,6380,6381} /var/log/redis
```

**配置主节点 (Master - 6379)**

创建并编辑 `/etc/redis/6379.conf`：

```
port 6379
bind 0.0.0.0  
daemonize yes
pidfile /var/run/redis_6379.pid
logfile /var/log/redis/redis-server-6379.log
dir /var/lib/redis/6379  
dbfilename dump-6379.rdb  
appendonly yes  
appendfilename "appendonly-6379.aof"
# 可选：设置密码，主从节点需一致
# requirepass YourStrongPassword
# masterauth YourStrongPassword
```

_关键点：主节点配置相对简单，重点是定义好基础路径和端口。_

**配置从节点 (Slaves - 6380 & 6381)**

创建并编辑从节点配置文件，例如 `/etc/redis/6380.conf`。其内容与主节点大部分相同，主要区别在于端口和相关文件路径，并且必须通过 `replicaof`指令指定主节点 。

```
port 6380
bind 0.0.0.0
daemonize yes
pidfile /var/run/redis_6380.pid
logfile /var/log/redis/redis-server-6380.log
dir /var/lib/redis/6380
dbfilename dump-6380.rdb
appendonly yes
appendfilename "appendonly-6380.aof"
# 核心配置：指定主节点
replicaof 127.0.0.1 6379
# 如果主节点设置了密码，从节点需要配置以下两项
# requirepass YourStrongPassword  # 从节点自身密码（若需要）
# masterauth YourStrongPassword   # 主节点的密码
```

配置文件 `/etc/redis/6381.conf`参照此格式，将其中所有 `6380`替换为 `6381`即可。

#### 2. 启动Redis实例
**要以root用户启动**
```
su
```
使用各自的配置文件启动三个Redis服务。

```
redis-server /etc/redis/6379.conf
redis-server /etc/redis/6380.conf
redis-server /etc/redis/6381.conf
```

启动后，使用 `ps aux | grep redis-server`命令检查是否有三个进程正常运行。

#### 3. 验证主从关系

这是检验配置是否成功的关键一步。

**检查主节点状态**

连接主节点，查看复制信息：

```
redis-cli -p 6379 info replication
```
![[Pasted image 20251123110842.png]]
在输出信息中，您应该能看到 `role:master`以及 `connected_slaves:2`，下面会列出两个从节点的连接信息 。

**检查从节点状态**

分别连接两个从节点查看状态：

```
redis-cli -p 6380 info replication
redis-cli -p 6381 info replication
```
![[Pasted image 20251123110922.png]]
它们的输出中应显示 `role:slave`和 `master_link_status:up`，这表明主从同步连接正常 。

**数据同步测试**

在主节点写入一个数据，然后在从节点查询，验证数据是否同步。

```
# 在主节点写入
redis-cli -p 6379 set "mykey" "Hello from Master"

# 在从节点读取 (注意：从节点默认只读，不能执行写操作)
redis-cli -p 6380 get "mykey"
redis-cli -p 6381 get "mykey"
```
![[Pasted image 20251123110945.png]]



![[Pasted image 20251122202552.png]]