- 需求背景：explain发现Using filesort
- 问题分析：
	当执行 `GROUP BY`时，数据库的核心任务是①将数据按指定字段分组，②然后对每个组进行聚合计算（如 `SUM`, `COUNT`）。**如果无法利用索引**，数据库通常会采用两种策略：
	1. **排序分组**：
		- 流程：
			1. 对所有数据进行排序，
			2. 顺序扫描完成分组。
		- 问题所在：这个过程可能需要在磁盘上创建**临时表**，并在排序时引发 **文件排序（Using filesort）​ 
	2. **哈希分组**：为每个分组构建一个**哈希表**。这通常在内存中进行，效率较高，
		- 问题：当数据量过大或内存不足时，同样会涉及磁盘操作 。
- 性能瓶颈：
	- **CPU密集型计算**：大规模数据的**排序**和**哈希计算**消耗大量CPU资源。
	- **高I/O压力**：当临时表或哈希表无法在内存中完成时，会使用磁盘，造成I/O瓶颈。
		- 诊断方式：使用 `EXPLAIN`分析查询时，在 `Extra`列出现 **`Using temporary`**（使用临时表）和 **`Using filesort`**（使用文件排序）
	- **数据倾斜加剧消耗**：如果某个分组键的值特别多（如日志中的某个特定错误码），会导致大部分计算资源都消耗在处理这一个分组上，这就是**数据倾斜**。
- 优化思路：
	- 避免或减少在磁盘上进行的大规模排序和临时表操作
	- 均衡化处理数据倾斜
- 具体措施：
	- 利用索引优化：
		- 优化原理：让 `GROUP BY`利用索引的有序性，不需要自己对数据排序
		- 优化思路：根据where，order by ，group by 使用的字段顺序**创建复合索引**，
			- 保证符合**最左前缀原则**。
				- 示例：如果查询是 `WHERE date_field = ? GROUP BY category`，最优的索引是 `(date_field, category)`。如果 `GROUP BY`后还有 `ORDER BY`，将排序字段也加入索引末尾，可以避免再次排序
			- 触发[[松散索引扫描]]：
				- 使用场景： 使用求MIN()和MAX()的聚合函数
				- 判断方式：执行计划中会出现 `Using index for group-by`​ 的提示
	-  SQL语句优化：减少处理量
		- 使用 WHERE 提前过滤：在 `GROUP BY`之前，通过 `WHERE`条件尽可能减少需要处理的数据行数
		- 谨慎使用 SELECT*：只选择需要的字段。如果所有字段都包含在索引中（覆盖索引），数据库可以仅通过索引完成查询，避免回表，提升性能
		- 避免在分组字段上使用函数：例如，`GROUP BY DATE(create_time)`会导致索引失效。可考虑使用计算列并为其建立索引
	- 数据库参数调优：提供资源保障
		- 增大排序缓冲区：例如，在MySQL中调整 `sort_buffer_size`参数 。
		- 调整临时表大小：例如，调整 `tmp_table_size`和 `max_heap_table_size`，使得临时表尽可能在内存中处理
- 兜底方案
	- 使用场景：实时性要求不高
	- **批处理**：在应用层（如Java程序）将大查询按时间范围等维度拆分成多个小查询，分批执行后合并结果。这能有效避免单次查询拖垮数据库，并实现进度可控 。
	- **异步处理与缓存**：对于报表类查询，可采用“查询结果缓存”策略。将聚合结果存入Redis等缓存，设定合理过期时间。后续请求优先读取缓存，定期由后台任务更新结果 。
	- **使用物化视图或OLAP引擎**：这是最彻底的方案。**物化视图**​ 会预先计算并存储 `GROUP BY`的查询结果，查询时直接读取，牺牲实时性换取极致速度。对于超大规模数据，可将其同步到 **ClickHouse**​ 或 **Doris**​ 等专为OLAP设计的系统中进行聚合分析