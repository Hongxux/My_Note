- CPU 缓存与主内存的速度鸿沟
	- 鸿沟：CPU 的运算速度（纳秒级）远快于主内存（RAM，毫秒级）—— 两者速度差可达数百甚至上千倍。
	- 为了弥补这个鸿沟，CPU 引入了**多级高速缓存（L1/L2/L3）** **和寄存器：**
		- 设计目的：减少CPU 访问慢速的主内存的次数
		- 组成：
			- 每个 CPU 核心有**专属**的 L1/L2 缓存
			- 多个核心**共享** L3 缓存；
		- 使用方式：
			- 程序执行时，数据会先从主内存加载到 CPU 缓存
			- 运算后再按需写回主内存；
- JMM工作内存：JAVA对**CPU 缓存 + 寄存器** 的抽象
	- 屏蔽不同 CPU 的缓存差异，保证 Java 程序的跨平台性。
	- 让线程能使用到高速的CPU缓存
- 衍生出可见性问题：
	- 工作内存与主内存的同步规则定义了线程修改的变量何时对其他线程可见