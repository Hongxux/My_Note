## Redis的需求背景
- Redis主从和Redis哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决:
	- 海量数据存储问题
		- 单机内存有限，无法存储持续增长的海量数据（如大型社交媒体的用户数据）
		- 垂直扩展（Scale-up）升级硬件成本高且存在物理上限
	- 高并发写的问题
		- 单机CPU处理能力、网络I/O和连接数有上限，无法满足极高的读写并发需求

## Redis分片集群的结构：多主多从结构
![[Pasted image 20251124100021.png]]
Redis分片集群的核心思想非常巧妙，它通过**去中心化**的架构和**分而治之**的策略，将多个Redis实例组织成一个统一的、可扩展的、高可用的数据库服务。其设计目标直指单机Redis的痛点：

- **突破内存容量限制**和**提升写并发能力**，
    - Redis所有数据都存放在内存中，单机的物理内存有限。
    - 即使挂载再多从节点，存储上限仍然受限于主节点的容量。(多个主节点)
- **获得高可用性**
    - 如果单机Redis宕机，[依赖](app://obsidian.md/%E4%BE%9D%E8%B5%96.md)该Redis的服务将完全不可用。
    - 即便配置了[主从复制](app://obsidian.md/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.md)🔗，如果主节点宕机，人工切换从节点成本很高。

### 核心架构：**多主多从**的去中心化架构
- 客户端请求可以访问集群任意节点，最终都会被转发到正确节点(路由)
	- 集群有多个主节点，每个主节点**负责一部分数据**
		- 提高并发写的性能
	- 每个主节点可以挂载若干**从节点**
		- 用于高可用
		- 提高并发读的性能
- 主节点之间通过ping检测彼此健康状态（类似于Redis哨兵机制）
	- 实现自动检测，故障转移和新主从状态的配置和通知

**好处：**

- **分摊压力**：每个主节点负责一部分哈希槽，处理对应数据的读写请求。这样，写压力和存储压力就被分摊到了多个主节点上，实现了水平的写扩展
- **[主从复制](app://obsidian.md/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.md)🔗**：每个主节点都可以配置一个或多个从节点。从节点通过异步复制保持与主节点的数据同步，主要提供**数据冗余**和**故障恢复**的能力。
- **故障转移**：当某个主节点宕机时，集群会通过内置的共识算法，自动从其从节点中选举出一个新的主节点来接管槽位，继续提供服务，从而实现高可用
- **容易扩容**：当数据量增加时，只需要新加节点D，重新分配部分哈希槽，集群即可扩容。

### 数据切分的思想：哈希槽

Redis集群的核心思想是**数据切分**。数据太多，单机放不下，我们就把它拆开存。

Redis集群引入了哈希槽（[Hash](app://obsidian.md/Hash.md)🔗 Slot），本质上是在Key和节点之间增加了一层固定映射表。

![[Redis 分片集群 2025-11-24 18.18.59.excalidraw]]

集群中总共有16384个哈希槽（0 ~ 16383）。

每个Key中的有效值通过CRC16算法计算出一个哈希值，
1. key有效值：
	- key中包含“{}”，并且“{}”中至少包含1个字符，“{}”中的部分是有效部分
	- key中不包含“{}”，整个key都是有效部分
		例如：key是num，那么就根据num计算，如果是{ithm}num，则根据ithm计算。
	- 因此如果想要把同一类数据保存到一个Redis实例，从而同一有效值
		- 同一类数据保存到一个Redis实例的原因：避免多次使用重定向
		- 同一有效值的实现方式：可以使用{}括起来相同的值

2. 计算方法是利用CRC16算法获得一个hash值，然后对16384提取余，得到的结果就是slot值
```
slot = CRC16(key) % 16384
```

3. 每个Redis节点负责一部分哈希槽：
![[Pasted image 20251124182616.png]]
![[b0507b1bd72a0af83c3cbaa3573c9041.jpeg]]
**优点：**

- 哈希槽数量固定不变，Key到槽的映射关系稳定。
- 新增或删除Redis节点时，只需要重新分配少量槽的数据即可，无需全量迁移。

### Redis分片集群的故障转移机制
![[3c51c3761d2aaa5dcb1c01af26b1e0f2.jpeg]]
## 搭建Redis分片集群
好的，在您现有的一主两从哨兵架构基础上，扩展搭建一个三主三从的Redis分片集群，是一个从“高可用”向“高可用+水平扩展”演进的重要步骤。由于架构有根本性不同，我们需要重新规划。

为了帮助您清晰了解整个搭建流程，我为您梳理了以下主要步骤的路线图：

```
flowchart TD
    A[前期准备与规划] --> B[配置所有Redis节点]
    B --> C[启动节点并创建集群]
    C --> D[验证集群状态与测试]
    D --> E[数据迁移与客户端切换]
```

下面，我们按照这个流程来详细操作。

###  第一步：规划与准备

分片集群的核心是**数据分片**和**高可用**。您现有的三个节点（6379, 6380, 6381）可以作为三个主节点（Master），但一个健壮的“三主三从”集群还需要三个从节点（Slave）。

|角色|IP地址|端口|说明|
|---|---|---|---|
|**Master 1**​|192.168.0.100|6379|利用现有节点|
|**Master 2**​|192.168.0.100|6380|利用现有节点|
|**Master 3**​|192.168.0.100|6381|利用现有节点|
|**Slave 1**​|192.168.0.100|6382|**需要新建**，作为Master 1的从节点|
|**Slave 2**​|192.168.0.100|6383|**需要新建**，作为Master 2的从节点|
|**Slave 3**​|192.168.0.100|6384|**需要新建**，作为Master 3的从节点|

**重要前提：**

- **停止哨兵服务**：为避免干扰，请先停止之前搭建的Redis哨兵服务。
    
- **备份数据**：**此操作会清空现有数据**。请务必先对现有Redis数据进行备份，集群创建完成后再考虑导入。
    

###  第二步：配置Redis节点

我们需要为六个节点创建各自的配置文件。关键配置项如下：

1. **创建配置目录和文件**：
    
    ```
    # 为每个节点创建独立的目录
    for port in 6379 6380 6381 6382 6383 6384; do
        sudo mkdir -p /etc/redis/cluster/${port}
        sudo mkdir -p /var/lib/redis/${port}
    done
    ```
    
2. **创建通用配置文件模板**（例如 `/etc/redis/cluster/redis-cluster.tmpl`）：
    
```
port ${PORT}  
bind 0.0.0.0  
  
# 集群配置  
cluster-enabled yes  
cluster-config-file nodes.conf  
cluster-node-timeout 5000  
  
# 持久化（建议开启）  
appendonly yes  
dir /var/lib/redis/${PORT}/  
  
# 安全设置（请修改为强密码）  
#requirepass your_secure_password_here  
#masterauth your_ecure_password_here  
  
# 关闭保护模式以便于测试，生产环境应配置防火墙  
protected-mode no  
daemonize yes
```
    
**注意**：`requirepass`和 `masterauth`的密码必须相同，这是集群节点间通信的基础。
    
3. **为每个端口生成具体配置**：
    
    ```
    for port in 6379 6380 6381 6382 6383 6384; do
        sudo sed "s/\${PORT}/$port/g" /etc/redis/cluster/redis-cluster.tmpl | sudo tee /etc/redis/cluster/${port}/redis.conf > /dev/null
        sudo chown -R redis:redis /etc/redis/cluster/${port}
        sudo chown -R redis:redis /var/lib/redis/${port}/
    done
    ```
    

###  第三步：启动服务并创建集群

1. **启动所有Redis实例**：
    _
```
    for port in 6379 6380 6381 6382 6383 6384;do
redis-server /etc/redis/cluster/$port/redis.conf
done

```
    
2. **创建分片集群**：
    
    使用 `redis-cli`命令一键创建集群，`--cluster-replicas 1`参数表示每个主节点分配1个从节点。
    
    ```
    redis-cli --cluster create --cluster-replicas 1 192.168.0.100:6379 192.168.0.100:6380 192.168.0.100:6381 192.168.0.100:6382 192.168.0.100:6383 192.168.0.100:6384 
    ```
    
    执行后，命令行会显示它提议的**主从分配方案**（例如，6382可能是6379的从节点）。请仔细核对，输入 `yes`确认即可完成集群创建。
    - 之前创建失败了，使用ps aux | grep redis-server检查，发现有两个实例的状态是TL(终止)，重新启动后恢复正常

###  第四步：验证与测试

1. **检查集群状态**：
    
    ```
    redis-cli -c -h 192.168.0.100 -p 6379 -a your_secure_password_here cluster nodes
    ```
    
    观察输出，应有3个节点的 `role`是 `master`，3个是 `slave`。并且所有 `16384`个哈希槽（hash slots）都应被分配完毕（`[OK] All 16384 slots covered`）。
    
2. **测试数据分片与高可用**：
    
    - **分片测试**：连接集群（使用 `-c`参数启用集群模式），设置几个不同的key，观察客户端是否自动在节点间重定向。
        
        ```
        redis-cli -c -h 192.168.0.100 -p 6379 -a your_secure_password_here
        127.0.0.1:6379> set key1 value1
        127.0.0.1:6379> set key2 value2 # 这两个key可能会被重定向到不同的节点
        ```
        
    - **高可用测试**：手动停止一个主节点（如6379），等待几秒后再次执行 `cluster nodes`命令。你应该会看到其对应的从节点（如6382）的角色自动从 `slave`提升为 `master`。
        
    
re
###  第五步：数据迁移与客户端切换

这是最关键的一步，关乎业务连续性。

- **数据迁移**：集群创建后是一个空数据集。您需要将之前备份的数据导入到新集群中。
    
    - **如果数据量不大**：可以编写脚本，通过 `redis-cli -c`连接集群，重新写入数据。
        
    - **如果数据量大**：可以考虑使用 `redis-cli --cluster import`命令，或者使用如 `redis-migrate-tool`等专业工具。
        
    
- **客户端配置**：
    
    - **不再需要**配置哨兵节点的地址。
        
    - 应用程序的Redis客户端需要**支持集群协议**。
        
    - 配置时，只需要填写集群中**任意一个或多个节点**的地址（IP:Port）即可，客户端会自动发现整个集群拓扑。例如，在Spring Boot中：
        
        ```
        spring:
          redis:
            cluster:
              nodes: 192.168.0.100:6379,192.168.0.100:6380,192.168.0.100:6381
            password: your_secure_password_here
        ```
        
    
## Redis集群相关命令
### 添加节点
 将新节点（192.168.0.100:6382）加入现有集群（以192.168.0.100:6379为例）
```
redis-cli -a your_secure_password_here --cluster add-node 192.168.0.100:6382 192.168.0.100:6379
```
![[Pasted image 20251124183430.png]]
- 指定一个分片集群的任一节点，即可定位到其相关联的集群
- 添加的节点默认身份是主节点，但是是一个空节点，没有被分配任何的哈希槽
- 可以使用`--cluster-slave`指定新增加的节点为从节点，并且使用`--cluster-master-id`指定其主节点

### 重新分哈希槽（迁徙哈希槽）
```
# 连接集群中任意节点执行即可
redis-cli -a your_secure_password_here --cluster reshard 192.168.0.100:6379
```
![[Pasted image 20251124192055.png]]
执行命令后，你会进入一个交互式界面，需要依次输入以下信息：

1. **迁移的哈希槽数量**：输入你希望分配给新节点的槽数量。Redis 集群总共有 16384 个槽。例如，在四主节点集群中，若想均分，可分配 4096 个槽 `(16384 / 4)`。
    ![[Pasted image 20251124192111.png]]
2. **目标节点 ID**：输入**新主节点的 ID**。这个 ID 可以在执行 `redis-cli -c -p 6379 cluster nodes`命令查看集群节点信息时找到。
3. **数据来源**：输入从哪里获取这些哈希槽：
    - **输入 `all`**：系统会**自动从所有现有的主节点中平均抽取**指定数量的槽。这是最推荐的方式，能保持集群数据均衡
    - **输入源节点 ID**：你也可以手动输入一个或多个现有主节点的 ID，然后输入 `done`结束指定。这种方式用于精确控制槽的来源。
4. **确认迁移计划**：命令会列出迁移方案，输入 `yes`确认后，迁移过程正式开始。

### 删除节点

####  第一步：确认节点信息

在开始删除之前，必须先明确要删除的节点的角色（主节点还是从节点）和ID。

1.  连接至集群任意节点，执行以下命令查看集群状态：
    ```bash
    redis-cli -c -h 192.168.0.100 -p 6379 cluster nodes
    ```
2.  分析命令输出。输出内容大致如下：
    ```
    a3c45f... 192.168.0.100:6379@16379 master - 0 162... 0 connected 0-5460
    24421f... 192.168.0.100:6380@16380 master - 0 162... 1 connected 5461-10922
    ...
    e9aac3... 192.168.0.100:6382@16382 slave a3c45f... 0 162... 0 connected
    ```
    ◦   角色：`master` 表示主节点，`slave` 表示从节点。

    ◦   节点ID：每行开头的长字符串（如 `a3c45f...`）。

    ◦   哈希槽：主节点行末尾会显示它负责的槽范围（如 `0-5460`）。


请记下你要删除的节点的ID和角色，这至关重要。

#####  第二步：迁移数据（仅针对主节点）

如果你要删除的是一个主节点，必须先将其负责的所有哈希槽迁移到其他主节点上。如果删除的是从节点，可以跳过此步。

假设你要删除端口为 `6380` 的主节点，其节点ID为 `24421f...`，它负责槽 `5461-10922`。

1.  执行重新分片命令：
    ```bash
    redis-cli --cluster reshard 192.168.0.100:6379
    ```
2.  根据提示操作：
    ◦   要移动多少槽？ 输入主节点当前负责的槽总数，例如 `5462`（从5461到10922，共5462个槽）。

    ◦   接收这些槽的节点ID是多少？ 输入集群中另一个主节点的ID（例如 `6379` 的节点ID）。

    ◦   从哪个节点移出这些槽？ 输入你要删除的主节点的ID（即 `6380` 的节点ID：`24421f...`）。

    ◦   输入 `done` 开始迁移。

3.  等待迁移完成。这个过程可能需要一些时间，取决于数据量的大小。

迁移完成后，再次执行 `cluster nodes` 命令，确认该主节点不再负责任何哈希槽（`connected` 后面没有槽范围信息）。

####  第三步：从集群中移除节点

无论删除主节点还是从节点，都使用以下命令。将 `端口号` 和 `节点ID` 替换为你要删除的节点的信息。

```bash
redis-cli --cluster del-node 192.168.0.100:6379 <要删除的节点ID>
```
例如，要删除 `6380` 节点：
```bash
redis-cli --cluster del-node 192.168.0.100:6379 24421f...
```

这个命令会通知集群中的其他节点忘记目标节点，并将其从集群配置中删除。

####  第四步：最终清理

节点从集群中移除后，还需要在操作系统层面进行清理。

1.  停止Redis服务：
    ```bash
    # 连接到要删除的节点并执行关闭
    redis-cli -h 192.168.0.100 -p 6380 shutdown
    ```
    如果上述命令无效，可以使用 `kill` 命令强制终止进程。
2.  （可选）删除数据文件：如果你确定不再需要这个节点的数据，可以删除其工作目录（由配置中的 `dir` 指定）下的所有文件，包括 `dump.rdb`、`appendonly.aof` 和 `nodes.conf`。这一步是不可逆的，请务必谨慎。

####  第五步：验证集群状态

节点删除后，务必检查集群是否健康。

1.  检查节点是否已消失：
    ```bash
    redis-cli -c -h 192.168.0.100 -p 6379 cluster nodes
    ```
    确认输出的节点列表中已经没有了你刚删除的节点。
2.  检查集群状态是否正常：
    ```bash
    redis-cli -c -h 192.168.0.100 -p 6379 cluster info
    ```
    确保输出中 `cluster_state:ok` 并且 `cluster_slots_ok:16384`。

### 数据迁移
![[c499bee10b98fbf442a93b2bf6ba1968.jpeg]]