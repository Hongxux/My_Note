
- 并发问题容忍性判断
	-  什么时候需要进行并发问题容忍性判断？什么时候不用？
		- 满足以下 3 个条件时，必须判断：
		    - 存在 “并发事务”：多个事务同时执行（而非单线程串行）；
		    - 操作 “共享数据”：事务间操作同一表 / 同一行数据（读 - 写、写 - 写冲突场景）；
		    - 结果 “影响业务规则”：业务规则定义见下文。
		-  不适用场景
			- 无并发干扰的场景：
				- 不存在并发事务：
					- 单线程执行：事务串行执行（如后台定时任务、批处理脚本），不存在事务间干扰，自然不会出现脏读、不可重复读、幻读；
				    - 纯写事务（如批量导入历史数据）且**无其他事务**同时读取该数据；
					- 操作独立数据：事务间操作不同表 / 不同行数据（如用户 A 修改自己的资料，用户 B 修改自己的资料），无数据共享，无并发干扰。
				- 不对共享数据进行操作：只读不写 
				    - 纯只读事务（如查询个人信息、静态数据展示）且不依赖 “多次读取一致性”（仅单次查询）；
			- 业务规则无依赖的场景
				- 数据操作结果不关联核心业务约束：
				    - 非核心统计 / 报表：仅用于**临时展示**，如实时在线人数、商品浏览量统计（误差可接受，**不影响业务决策**）；
				    - 临时数据处理：如缓存同步、日志写入（即使出现并发干扰，也可通过后续同步修正，无实际损失）。
			-  非关系型数据库 / 无事务支持的场景
				- 数据库不支持 ACID 事务：如 Redis（单线程模型，无事务并发问题）、MongoDB（默认无严格事务隔离级）；
				- 未使用事务包裹的操作：单个 SQL 语句（非事务内多次操作），不存在 “同一事务内多次读取” 的场景，自然不会出现不可重复读、幻读（仅需考虑写 - 写冲突，无需判断容忍性）。
	- 核心逻辑：取舍
		- 取舍的前提：不违背业务核心价值
		- 取舍的目的：放弃部分的即时一致性或绝对正确性，换取系统的高性能
			- 隔离级别越高，数据一致性越强，但锁粒度越大 / 并发控制开销越高，吞吐量越低；
			- 隔离级别越低，并发性能越好，但可能出现脏读、不可重复读、幻读等并发问题；
	- 能否容忍某个并发问题取决于：该并发问题是否会导致 “**业务规则失效**” 或 “**不可逆损失**”。
		- 核心定义：
			- **业务规则**：**数据约束、逻辑流程或合规要求**
				- 脏读导致规则失效：用户 A 转账给用户 B，事务 B（B 的余额更新）未提交就被事务 A（查询 B 的余额）读取，若 B 回滚，A 误以为转账成功并触发 “到账通知”，违背 “仅当转账提交后才发送通知” 的规则；
				- 不可重复读导致规则失效：电商库存扣减事务中，先查询库存为 10 件（规则：库存≥购买量才能扣减），期间其他事务修改库存为 5 件并提交，导致本事务扣减 8 件后库存变为 - 3 件，违背 “库存不能为负” 的规则；
				- 幻读导致规则失效：财务批量对账事务中，多次执行 “查询今日未对账订单”（规则：所有订单必须对账一次），期间新增未对账订单导致部分订单漏对账，违背 “对账完整性” 规则。
			- **不可逆损失**：
				- 定义不可逆：
					- 无法通过技术手段或业务流程恢复的损失（**无法技术恢复**）
					- 恢复成本远大于损失本身（**恢复成本高无实际意义**）
		- 判断逻辑：
			- 若不会导致**业务规则失效**，则可容忍；
			- 若会导致**业务规则失效**，则进一步判断是否会引发**不可逆损失**
				- 若会，零容忍；
				- 若仅为可修复的规则失效，可结合性能成本权衡是否容忍。
	- 脏读：什么时候能容忍--**是否容忍 “读取未提交的无效数据”？**
		- 脏读的问题：事务读取了 “未提交且可能被回滚” 的临时数据，导致数据从根源上是 **“无效的”**。
		- 核心风险：基于无效数据做决策，必然导致决策错误
		- 可容忍场景特征：**非决策类实时场景，数据用于展示而非关键操作，错误无实质损失**
			- 允许偶尔出现无效数据。
			- 数据仅用于 “实时展示”“临时统计”，数据错误无实质损失（如用户体验轻微影响，无金钱、合规风险）；
		- 常见场景：
			- 例如：实时监控面板（如服务器 CPU 使用率、网站实时访问量）
				- 理由： 监控数据需 “**秒级更新**”，即使读取到未提交的临时数据（如某条访问记录未最终写入），也不影响**整体**监控趋势，用户可接受轻微波动；
			- 例如：非核心数据统计（如 APP 内 “今日热门商品浏览次数” 临时展示）
				- 理由：
					- 统计结果**仅用于用户参考**，不涉及**库存**扣减、**订单**结算等关键操作；
					- 即使数据有偏差（如某用户的浏览记录未提交被统计），后续会被修正，无实质损失。
			- 例如：草稿箱实时预览（如用户编辑文章时，实时展示字数统计、预览效果）
				- 理由：草稿未提交前的临时数据读取，即使因回滚导致预览内容无效，仅影响用户编辑体验，无其他风险；需实时反馈编辑结果，不能等待事务提交。
	- 不可重复读：什么时候能容忍？--**是否容忍 “同一事务内多次读同一数据不一致”？**
		- 问题：事务 A 同一条件下多次读取同一数据，事务 B 修改并提交该数据，导致 A 前后读取结果不一致。
		- 可容忍场景特征：**事务内无需依赖历史数据做决策，且需实时更新的高并发场景**
			- 业务允许 “同一事务内多次查询看到最新提交的数据”；
			- 数据更新是 “正常业务逻辑”，用户 / 系统可接受结果变化；
			- 高并发读写场景，需平衡性能与一致性（优先保证并发吞吐量）。
		- 常见场景：
			- 电商订单列表查询（用户多次刷新订单状态）
				- 理由：
					- 用户刷新列表时，允许看到最新的订单状态（如 “待付款” 变为 “已付款”），这是符合用户预期的；
					- 若强制 “可重复读”，用户需重新打开页面才能看到最新状态，体验反而变差。
			- 社交平台动态 / 评论展示（如朋友圈、短视频评论）
				- 理由：用户多次查看同一动态时，允许看到新增的评论、点赞数；若限制不可重复读，会导致 “数据滞后”，影响用户体验；且无实质损失。
			- 商品详情页价格 / 库存展示（非下单阶段）
				- 理由：用户浏览商品时，价格 / 库存可能被商家修改并提交，多次查看看到最新数据是合理的；下单阶段会通过锁机制保证一致性，浏览阶段无需严格的可重复读。
	- 幻读：什么时候能容忍？---**是否容忍 “同一事务内多次范围查询行数不一致”？**
		- 问题：事务 A 同一条件下多次查询结果集，事务 B 插入 / 删除符合条件的记录并提交，**导致 A 前后结果集行数不一致**。
		- 不可容忍的场景： **依赖结果集行数 / 范围做关键决策**
			- 库存盘点 / 批量扣减（如 “查询所有库存低于 10 的商品并补货”）：若盘点过程中新增了库存低于 10 的商品，会导致补货遗漏；
			- 金融批量转账（如 “向所有满足条件的用户发放优惠券 / 补贴”）：若事务内多次查询用户列表行数不一致，会导致漏发或多发；
			- 数据迁移 / 同步（如 “同步某时间段内的所有订单数据”）：行数变化会导致同步不完整，影响数据一致性。
