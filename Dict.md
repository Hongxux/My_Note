- 需求背景：
	- 我们知道Redis是一个键值型(Key-Value Pair)的数据库，我们可以根据键实现快速的增删改查。而键与值的**映射关系**正是通过Dict来实现的。
	- 原来的哈希表进行扩容的方式是一次性扩容，Redis是单线程的，这样的扩容方式会导致Redis服务出现一段时间的暂停
- 解决措施：作为Redis键值型存储的一个大结构，同时也是hash数据结构在一定情况下的底层实现
	- 有三个数据结构
		- 最外层的结构一个dict
			- 存储两个哈希表的指针，一个哈希表只有在扩容阶段进行的时候才使用
			- 哈希扩容的控制字段
				- 在不进行rehash 的时候为-1
				- 在进行rehash 的时候为指向下一个需要rehash 的桶
		- 哈希表
			- 存储一个dictEntry数组，即桶
			- 存储桶的个数size,以及用于hash的size-1得到的掩码sizemask
			- 存储已经被使用的桶的个数used
		- 哈希节点：
			- 存储一个键值对
			- 为了解决哈希冲突，包含一个 `next`指针
	- 构建渐进性式哈希扩容：在每一次进行增删改查的时候的时候，进行rehash。如果长时间没有操作，则设定一个定时任务，每隔多少ms进行一次批量迁移
		- 实现的机制是Dict中的一个字段rehashinx，用于指示下一个需要rehash 的桶
		- 在哈希扩容的时候，确保只增加不减少
			- 查询操作分别对两个哈希表进行
			- 插入操作对新的哈希表进行
			- 删除和修改操作对两个表进行
	- 哈希扩容和缩容
		- 哈希扩容
			- 触发时机
				- 检查时机：在每次新增操作的时候，检查负载因子
				- 触发条件：
					- 大于1的时候考虑，要确保Redis没有在进行RDB或者AOF，避免占用大量cpu
					- 大于5的时候强制扩容
			- 扩容大小：大于等于used+1的2^n
		- 哈希缩容
			- 触发时机，负载因子小于0.1
			- 缩容大小：至少为4，具体是第一个大于等于used+1的 2^n
	- 解决哈希冲突的方式是链地址法
		- 具体实现是链表
		- 链表采用的是头插法
			- 方便插入：可以减少插入的时候遍历的时间
			- 方便查询新插入的键值对被再次访问的可能性更大（时间局部性原理），将其放在链表头部可以使下次访问更快













- Dict的结构：哈希表（dictht）、哈希节点（dictEntry）、字典（dict）![[Pasted image 20251126162227.png]]
	- 哈希表![[Pasted image 20251126160752.png]]
		- used：由于哈希冲突的存在，是可能出现used>size的情况
	- 哈希节点![[Pasted image 20251126161006.png]]
		- next：哈希冲突的解决方法--**链地址法**
			- 在链表头插入新元素：避免找到链表尾的过程
		- v：存储值，使用联合体使得它可以存放指针、多种整数或浮点数，非常灵活
			- void * 不代表空，而代表任意类型
		- key：存储键，支持多种数据类型
			- 当我们向Dict添加键值对时，Redis首先根据key计算出hash值(h)，然后利用h&sizemask来计算元素应该存储到数组中的哪个索引位置。
				- h&sizemask等价于h%size，但是运算速度更快
	- 字典![[Pasted image 20251126161824.png]]
		- 功能性字段：
			- 哈希运算相关
				- type：不同情况下使用不同哈希函数
				- privdata
			- rehash相关：
				- rehashidx
				- pauserehash
		- `ht[2]`：为了哈希扩容而准备
			- `ht[0]`：正常情况下，所有数据都存在这里。
			- `ht[1]`：当需要扩容或缩容时，会分配`ht[1]`，然后进行**渐进式 rehash**，将数据分批从`ht[0]`迁移到`ht[1]`
- 哈希扩容：
	- 时机：Dict在每次新增键值对时都会检查负载因子(LoadFactor=used/size)，满足以下两种情况时会触发哈希表扩容
		- 哈希表的 LoadFactor>=1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程
		- 哈希表的 LoadFactor>5
	- 扩容的目标大小：第一个大于等于used+1的 2^n
- 哈希收缩：
	- 时机：每次删除元素时，也会对负载因子做检查，当LoadFactor<0.1时，会做哈希表收缩
	- 收缩的目标大小：
		- used<4：收缩成4
		- used>4：第一个大于等于used+1的 2^n
- dictExpand：本身并不直接迁移数据，而是做预处理
	- 对参数检查和对redis目前的状态进行判断
	- 分配并初始化新哈希表（`ht[1]`）
		- 计算新的哈希表容量realsize：找第一个大于等于size 的2^n
		- 设置sizemask和used个数
		- 分配内存
	- 设置标志位，告诉redis，准备进行rehash
		- `d->rehashidx = 0;`：将 rehashidx 从 -1 设
- rehash：对哈希表中的每一个key重新计算索引，插入新的哈希表![[Pasted image 20251126170542.png]]
	- 需求背景：不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的size和sizemask变化，而key的查询与sizemask有关。因此必须对哈希表中的每一个key重新计算索引，插入新的哈希表，这个过程称为rehash
	
	- 流程：在dictExpand的基础上进行
		1. 将`dict.ht[0]`中的每一个dictEntry都rehash到`dict.ht[1]`![[Pasted image 20251126170657.png]]
			- 时机：在启动rehash进行状态（rehashidx>=0）的时候，在每次增删改查的时候
				- 为了避免长时间对大量数据进行rehash，导致主线程阻塞
			- rehash的对象：每次对rehashidx这个hashEntry进行rehash
			- 更新：
				- 新增操作，则直接写入`ht[1]`
				- 查询、修改和制除则会在`dict.ht[0]`和`dict.ht[1]`依次查找并执行。
					- 这样可以确保`ht[0]`的数据只减不增，随着rehash最终为空
				- rehash完成后，rehashidx++，指向下一个rehash目标
		2. 全部完成之后：将`dict.ht[1]`赋值给`dict.ht[0]`，给`dict.ht[1]`初始化为空哈希表，释放原来的`dict.ht[0]`的内存![[Pasted image 20251126170737.png]]