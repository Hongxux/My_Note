积极队列管理（Active Queue Management, AQM）是计算机网络中一个至关重要的概念，它主要**作用于网络设备（如路由器、交换机）**，与端系统上的拥塞控制算法（如TCP）协同工作，共同管理网络拥塞。

---

### 1. 核心定义 / 定位 / 关系

​**核心定义：​**​

​**积极队列管理（AQM）​**​ 是一系列运行在网络设备缓冲区（队列）上的算法的总称。其核心思想是：​**在缓冲区被完全填满之前，主动地、以一定的概率丢弃或标记为[[ECN]]（显式拥塞通知，支持ECN的接收端会通过ACK包将拥塞信号回送给发送端）数据包**，从而向发送端提供早期拥塞信号，避免[[TCP的全局同步|全局同步（Global Synchronization）]]和[[TCP的锁死|锁死（Lock-out）]]现象。

​**定位：​**​

- ​**目标：​**​
    
    1. ​**控制队列长度：​**​ 维持较小的平均队列长度，从而**降低排队延迟**​（解决Bufferbloat问题）。
        
    2. ​**避免尾丢：​**​ 在队列溢出前提前丢包，打破TCP流的同步行为，提高链路利用率。
        
    3. ​**管理拥塞：​**​ 为多个流提供公平的服务或根据策略进行差异化服务。
        
    
- ​**方法论：​**​ 主动干预。与传统“尾丢队列”（Tail-drop FIFO，被动等待队列满再丢包）的被动方式截然不同。
    
- ​**层级定位：​**​ 属于网络层的拥塞避免机制，是IP层对传输层（主要是TCP）提供的**一种显式的拥塞反馈**。
    

​**关系：​**​

- ​**与TCP的关系：​**​ ​**协同合作**。TCP是端到端的拥塞控制，而AQM是网络辅助的拥塞控制。AQM通过丢包或ECN标记向TCP发送端提供更及时、更精确的拥塞信号，TCP据此调整发送窗口。二者共同构成了完整的拥塞控制体系。
    
- ​**与路由器的关系：​**​ AQM是路由器调度器的一部分，管理着输出端口的队列。
    

### 2. 触发条件 / 使用情景

​**触发条件：​**​

AQM算法通常基于**队列状态**​（如平均队列长度、排队延迟）来周期性地或由数据包到达事件触发其决策逻辑。

​**使用情景：​**​

1. ​**所有网络瓶颈链路：​**​ 尤其是在带宽延迟积（BDP）较大或流量突发性强的链路中。
    
2. ​**解决[[Bufferbloat(缓冲区膨胀)]]：​**​ 在家庭网关、企业级路由器等设备中部署AQM（如FQ-CoDel）至关重要，因为这些设备的缓冲区通常很深，极易导致数百毫秒的延迟。
    
3. ​**需要低延迟和高吞吐的场景：​**​ 在线游戏、视频会议、实时音视频通信等对延迟和抖动敏感的应用，极大地受益于部署了AQM的网络。
    
4. ​**数据中心网络：​**​ 数据中心对延迟的要求极为苛刻，AQM是保证低尾延迟（Tail Latency）的关键技术之一。
    

### 3. 工作原理 / 具体实现

AQM有多种具体实现，最经典和具有代表性的是**随机早期检测（Random Early Detection, RED）​**。我们以RED为例说明其工作原理。

​**RED算法的核心机制：​**​

RED维护一个**指数加权移动平均（EWMA）​**​ 的队列长度 `avg_q`，以避免对瞬时流量的突发过于敏感。

它设定两个阈值：

- ​**最小阈值（min_th）：​**​ 平均队列长度的下限。
    
- ​**最大阈值（max_th）：​**​ 平均队列长度的上限。
    

以及一个**最大丢弃概率（max_p）​**。

其工作流程如下：

1. ​**计算平均队列长度：​**​ `avg_q = (1 - w_q) * avg_q + w_q * current_q`（`w_q`是权重因子）
    
2. ​**决策：​**​
    
    - ​**如果 `avg_q < min_th`：​**​ 队列空闲，​**不丢包**。所有数据包入队。
        
    - ​**如果 `min_th <= avg_q < max_th`：​**​ 监测到**轻度拥塞**。算法进入**随机丢弃**状态。对每个到达的数据包，以概率 `p`将其丢弃（或标记ECN）。概率 `p`从 0 线性增长到 `max_p`。
        
        `p = max_p * (avg_q - min_th) / (max_th - min_th)`
        
    - ​**如果 `avg_q >= max_th`：​**​ 监测到**重度拥塞**，队列即将满。算法转为**尾丢模式**，所有新到达的数据包都被丢弃。
        
    

​**其他现代AQM算法：​**​

- ​**CoDel (Controlled Delay)：​**​ 不再基于队列长度，而是**基于排队延迟**。如果数据包在队列中的停留时间超过了预设的目标延迟（target），则开始丢包。它更直接地控制了延迟。
    
- ​**PIE (Proportional Integral controller Enhanced)：​**​ 使用比例积分控制器，根据当前排队延迟与目标延迟的差值，动态调整丢包概率。旨在高负载下保持稳定的队列延迟。
    
- ​**FQ-CoDel (Fair Queuing + CoDel)：​**​ 结合了流隔离（Fair Queuing）和基于延迟的AQM（CoDel）。它首先将流量分成多个流（Flow），然后对每个流单独运行CoDel算法。这既能保证流之间的公平性，又能控制每个流的延迟，是Linux系统中的默认队列规则。
    

### 4. 预防措施 / 解决措施 / 潜在问题

​**潜在问题：​**​

1. ​**参数配置复杂（特指RED）：​**​ 经典RED的 `min_th`, `max_th`, `max_p`, `w_q`等参数对网络特性非常敏感，难以手动调优以适应所有流量模式，因此曾被称为“配置不了RED”。
    
2. ​**与非响应流（Non-responsive Flows）的交互：​**​ 例如UDP流，它们会忽略AQM的丢包信号。需要与流公平队列（如FQ）结合使用来隔离和惩罚这些流。
    
3. ​**对流量模型的假设：​**​ 一些早期AQM算法设计时基于的流量模型可能与现代互联网流量不符。
    

​**解决与预防措施：​**​

- ​**采用无参数或自适应的现代AQM：​**​ ​**CoDel**和**PIE**​ 是现代AQM的典范。它们**没有（或极少有）需要手动配置的参数**。它们通过测量排队延迟等直接指标来自适应地调整行为，鲁棒性更强，部署更简单。
    
- ​**与流公平队列结合：​**​ 采用 ​**FQ-CoDel**​ 或 ​**FQ-PIE**​ 等组合方案，可以有效处理非响应流和流间的公平性问题。
    
- ​**启用ECN：​**​ 鼓励端到端部署**显式拥塞通知（ECN）​**。AQM算法可以对数据包进行标记（而不是丢弃），支持ECN的接收端会通过ACK包将拥塞信号回送给发送端，发送端从而在丢包前就降低速率。这**避免了不必要的丢包，提升了整体性能**。
    

### 5. 面试官可能关心的方面与答案

​**Q1: AQM（如RED）和传统的尾丢（Tail-drop）队列最主要的区别是什么？​**​

​**A1:​**​ 最核心的区别在于**提供拥塞信号的时机和方式**。

- ​**尾丢队列**是**被动**的，只在缓冲区完全满时**一次性丢弃所有后续包**。这会导致：
    
    1. ​**全局同步：​**​ 所有正在传输的TCP连接同时超时、同时进入慢启动，造成链路利用率剧烈波动。
        
    2. ​**高延迟：​**​ 允许队列填满，意味着排队延迟始终很高（Bufferbloat）。
        
    
- ​**AQM（如RED）​**​ 是**主动**的，在队列满之前就**开始随机、渐进地丢包**。这可以：
    
    1. ​**避免全局同步：​**​ 随机丢包使得只有部分TCP连接减速，流之间得以解耦。
        
    2. ​**保持低延迟：​**​ 通过主动控制将平均队列长度维持在一个较低的水平。
        
    3. ​**高链路利用率：​**​ 避免链路因全局同步而空闲。
        
    

​**Q2: 为什么RED算法要使用平均队列长度（avg_q）而不是瞬时队列长度（current_q）？​**​

​**A2:​**​ 使用平均队列长度是为了**过滤掉流量的短期突发（Short-term Bursts）​**，使算法对瞬时变化不那么敏感。

- 网络流量本质上是突发的。瞬时队列可能因为一个突发而瞬间升高，但这并不一定意味着持续拥塞。如果基于瞬时值丢包，会**过度惩罚**正常的流量突发，导致链路利用不足。
    
- 平均队列长度（通过EWMA计算）能更好地反映**持续的、长期的拥塞趋势**。只有当平均队列长度持续较高时，RED才认为发生了需要干预的拥塞，从而做出丢包决策。这增强了算法的稳定性和鲁棒性。
    

​**Q3: 解释一下Bufferbloat问题，以及AQM是如何解决这个问题的。​**​

​**A3:​**​

- ​**Bufferbloat（缓冲区膨胀）：​**​ 指网络设备中**过深**的缓冲区导致数据包经历**极长排队延迟**的现象。其根源在于：基于丢包的TCP算法（如Reno/Cubic）的目标是填满缓冲区，而设备制造商为了吸收突发，提供了非常深的缓冲区。结果就是，即使链路空闲，数据包也要在队列中等待很长时间才能被发送。
    
- ​**AQM的解决方案：​**​ AQM通过**主动管理队列长度**来直接解决此问题。例如，CoDel算法直接设定一个目标延迟（如5ms）。一旦数据包的排队时间超过该目标，就立即丢包，强制发送端减速。这确保了队列永远不会被填满，从而将延迟稳定在一个很低的水平上，从根本上消除了Bufferbloat。