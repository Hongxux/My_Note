### 第一步：快速确认整体内存状况
首先，我们会用 `INFO memory` 命令来获取最核心的指标，这是所有排查的起点。

```bash
redis-cli> INFO memory
```

你需要重点关注这几个值：
*   **`used_memory`**：Redis为了存储所有键值对**实际分配**的内存总量，可以理解为“有效数据”占用的内存。
*   **`used_memory_rss`**：Redis进程在操作系统中**实际占用的物理内存**大小，也就是你用 `top` 或 `ps` 命令看到的值。
*   **`mem_fragmentation_ratio`**：这就是**内存碎片率**，计算公式是 `used_memory_rss / used_memory`[[1]][[2]]。

**如何判断？**
*   如果 `used_memory_rss` 远大于 `used_memory`（比如碎片率 > 1.5），那基本可以确定存在**严重的内存碎片**[[3]][[4]]。比如一个真实案例中，数据只有3GB，但操作系统却分配了7.5GB，碎片率高达2.5[[5]]。
*   如果 `used_memory` 本身就很大，但你觉得实际数据没那么多，那可能是别的原因，比如存在“大Key”或SDS的预分配空间过大。

### 第二步：深入排查，定位具体原因
确认了内存异常后，就要分头行动，找出“元凶”。

**1. 排查“大Key”和SDS的预分配问题**
SDS的扩容策略（小于1MB时翻倍，大于1MB时每次扩1MB）可能导致大字符串的实际占用空间远超其数据本身[[6]]。要找到这些“嫌疑犯”，可以用以下方法：

*   **使用 `redis-cli --bigkeys` 命令**：这个命令会扫描整个实例，找出每种数据类型中最大的几个Key。它能快速帮你定位到那些体积异常大的String、Hash、List等[[7]]。
*   **使用 `DEBUG OBJECT <key>` 命令**：对于疑似的大Key（特别是String类型），可以用这个命令查看其序列化长度（`serializedlength`）。注意，这个命令会阻塞当前连接，不要在线上频繁使用。
*   **编写扫描脚本**：如果实例很大，`--bigkeys` 可能不够精确。更常见的做法是写一个Lua脚本或使用 `SCAN` 命令遍历所有Key，用 `STRLEN`、`HLEN`、`LLEN` 等命令估算每个Key的大小，找出TOP N的大Key。

**2. 验证内存碎片**
如果碎片率很高，我们还需要看看碎片的构成和趋势。

*   **查看详细碎片信息**：在Redis 4.0及以上版本，`INFO memory` 命令会输出更多细节，比如 `mem_fragmentation_bytes`（碎片的绝对字节数），这能让你更直观地感受问题规模。
*   **分析业务模式**：内存碎片通常由频繁的更新、删除操作导致[[8]]。你需要回顾一下业务：是否有很多Key在频繁地被 `APPEND`、被修改长度、或者被删除？这种模式最容易产生碎片。

### 第三步：基于真实案例的解决方案
定位到问题后，解决方案取决于具体原因：

**情况一：确认是“大Key”导致（SDS预分配是帮凶）**
*   **解决方案**：优化数据结构。比如把一个存储长文本的String大Key，拆分成多个小的String Key，或者改用Hash来分段存储。如果大Key是集合类型，可以考虑按业务维度拆分。
*   **真实背景**：在很多电商或社交场景中，用户缓存的对象可能非常庞大。直接序列化成一个大String存入Redis，每次读写都传输巨大数据包，不仅浪费内存，还阻塞网络。拆分后能显著降低单次操作的成本。

**情况二：确认是内存碎片过高**
*   **解决方案A（重启大法）**：最简单粗暴的方法是**重启Redis实例**。重启后，内存会重新分配，碎片被清除[[9]]。但这对线上服务影响巨大，一般只在低峰期或有完整高可用方案（如主从切换）时使用。
*   **解决方案B（自动碎片整理）**：这是更优雅的方案。从Redis 4.0开始，支持了**内存碎片自动整理**功能[[10]]。你可以在配置中开启：
    ```bash
    config set activedefrag yes
    ```

    同时，可以设置触发整理的阈值，比如当碎片率超过1.5时才开始整理，并且限制整理过程消耗的CPU资源，避免影响正常服务[[11]]。
*   **真实背景**：一个典型的案例是，一个内容推荐系统会频繁更新用户的热门列表（频繁修改、删除旧数据，插入新数据）。运行几周后，虽然总数据量没变，但内存碎片率可能从1.1飙升到1.8以上，导致明明有内存却无法写入新数据。这时，在业务低峰期（如凌晨）开启自动碎片整理，就能平稳地回收内存[[12]]。

**情况三：混合情况（既有大Key，也有碎片）**
*   **解决方案**：组合拳。先通过拆分、优化数据结构消除大Key，减少不必要的内存占用和分配。然后再观察碎片率，如果依然很高，再考虑在低峰期开启碎片整理。

